{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline\n",
    "import glob as g\n",
    "import re\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spamfiles = g.glob('./spam/spam/*.txt')\n",
    "hamfiles = g.glob('./spam/ham/*.txt')\n",
    "testfiles = ['./spam/test/' + str(i) + '.txt' for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_process_files(files):\n",
    "    txts = list()\n",
    "    for file in files:\n",
    "        txt = open(file, \"r\", encoding='utf-8', errors='ignore').read()\n",
    "        txt = txt.replace('\\r\\n', ' ')\n",
    "        txts.append(txt)\n",
    "    return txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spams = load_process_files(spamfiles)\n",
    "hams = load_process_files(hamfiles)\n",
    "tests = load_process_files(testfiles)\n",
    "trains = spams + hams\n",
    "all = trains + tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Ns = len(spams); Nh = len(hams); Nt = len(tests)\n",
    "validate_n = 10000\n",
    "vectorizer = TfidfVectorizer(min_df=0.05)\n",
    "\n",
    "data = vectorizer.fit_transform(all).toarray()\n",
    "train_data = data[:-10000]\n",
    "test_data = data[-10000:]\n",
    "\n",
    "spam_data = train_data[:Ns]\n",
    "spam_validate = spam_data[validate_n:]\n",
    "\n",
    "ham_data = train_data[Ns:]\n",
    "ham_validate = ham_data[validate_n:]\n",
    "\n",
    "spam_prior =  math.log(1.0 * Ns / (Ns  + Nh))\n",
    "ham_prior = math.log(1.0 * Nh / (Ns  + Nh))\n",
    "\n",
    "c = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gaussian_mean_cov(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.cov(data, rowvar=0)\n",
    "    return mu, sigma\n",
    "\n",
    "\n",
    "def lda_train(spam, ham, all):\n",
    "    x = normalize(all.astype(np.float32))\n",
    "    sigma = np.cov(x, rowvar=0)\n",
    "    mu1, _ = gaussian_mean_cov(spam)\n",
    "    mu2, _ = gaussian_mean_cov(ham)\n",
    "    m1 = multivariate_normal(mu1, sigma + c * np.identity(sigma.shape[0]))\n",
    "    m2 = multivariate_normal(mu2, sigma + c * np.identity(sigma.shape[0]))\n",
    "    return m1, m2\n",
    "\n",
    "\n",
    "def qda_train(spam, ham):\n",
    "    mu1, sigma1 = gaussian_mean_cov(spam)\n",
    "    mu2, sigma2 = gaussian_mean_cov(ham)\n",
    "    m1 = multivariate_normal(mu1, sigma1 + c * np.identity(sigma1.shape[0]))\n",
    "    m2 = multivariate_normal(mu2, sigma2 + c * np.identity(sigma2.shape[0]))\n",
    "    return m1, m2\n",
    "    \n",
    "\n",
    "def test(x, spam_m, ham_m):\n",
    "    y = list()\n",
    "    for sample in x:\n",
    "        spam_y = spam_m.logpdf(sample) + spam_prior\n",
    "        ham_y = ham_m.logpdf(sample) + ham_prior\n",
    "        y.append(np.argmax([ham_y, spam_y]))\n",
    "    return y\n",
    "\n",
    "\n",
    "def evaluate(spam_data, ham_data, spam_m, ham_m):\n",
    "    spam_y = test(spam_data, spam_m, ham_m)\n",
    "    ham_y = test(ham_data, spam_m, ham_m)\n",
    "    correct = np.count_nonzero(spam_y) + (len(ham_y) - np.count_nonzero(ham_y))\n",
    "    total = len(spam_y) + len(ham_y)\n",
    "    return 1.0 * correct / total\n",
    "\n",
    "\n",
    "def batch_train_and_evaluate(spam_data, ham_data, spam_validate, ham_validate, categories, type=\"LDA\"):\n",
    "    errors = []\n",
    "    for size in categories:\n",
    "        spam_m, ham_m = qda_train(spam_data[:size, :], ham_data[:size, :])\n",
    "        if type == \"LDA\":\n",
    "            all = np.concatenate((spam_data, ham_data), axis=0)\n",
    "            spam_m, ham_m = lda_train(spam_data[:size, :], ham_data[:size, :], all)\n",
    "        err = evaluate(spam_validate, ham_validate, spam_m, ham_m)\n",
    "        errors.append(err)\n",
    "    \n",
    "    plt.plot(categories, errors, 'ro')\n",
    "    plt.axis([min(categories)-10, max(categories)+10, -0.1, max(errors)+0.1])\n",
    "    plt.title(\"{} Error rate\".format(type)) \n",
    "    return spam_m, ham_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (12015,345) (11687,345) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8a2c7bbf9804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlda_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspam_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LDA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mqda_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspam_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"QDA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-41eea29bb1ec>\u001b[0m in \u001b[0;36mbatch_train_and_evaluate\u001b[0;34m(spam_data, ham_data, spam_validate, ham_validate, categories, type)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mspam_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqda_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"LDA\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mspam_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspam_data\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mham_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspam_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mham_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (12015,345) (11687,345) "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "categories = [100, 200, 500, 1000, 2000]\n",
    "lda_models = batch_train_and_evaluate(spam_data, ham_data, spam_validate, ham_validate, categories, type=\"LDA\")\n",
    "qda_models = batch_train_and_evaluate(spam_data, ham_data, spam_validate, ham_validate, categories, type=\"QDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "lda_y = test(test_data, lda_models[0], lda_models[1])\n",
    "qda_y = test(test_data, qda_models[0], qda_models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = lda_y, columns=[\"Category\"]) \n",
    "df.index.name = \"Id\"\n",
    "df.to_csv(\"./spam.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
